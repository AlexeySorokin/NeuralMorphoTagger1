{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "from pyparadigm.paradigm import LcsSearcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = \"/home/alexeysorokin/data/neural_tagging/data/low-resource/evk-sample.train.ud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_LM.UD_preparation.extract_tags_from_UD import read_tags_infile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alexeysorokin/data/neural_tagging/data/low-resource/evk-sample.train.ud\n"
     ]
    }
   ],
   "source": [
    "tag_sents, source_sents, lemma_sents = read_tags_infile(infile, to_lower=True, return_source_words=True, return_lemmas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['INTJ',\n",
       "  'ADV',\n",
       "  'PART',\n",
       "  'VERB,Mood=Ind|Number=Sing|Person=1|Tense=Past|VerbForm=Fin',\n",
       "  'PRON,Case=Nom|Number=Sing|Person=1|PronType=Prs',\n",
       "  'NOUN,Case=Dat|Number=Sing',\n",
       "  'INTJ'],\n",
       " ['nu', 'idu', 'ka', 'baldit͡ʃaːw', 'bi', 'mohaduː', 'aha'],\n",
       " ['nu', 'idu', 'ka', 'baldi', 'bi', 'moha', 'aha'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_sents[0], source_sents[0], lemma_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'VERB': 4172, 'NOUN': 2607, 'DET': 218, 'PRON': 594, 'PROPN': 201, 'ADV': 95, 'ADJ': 146, 'INTJ': 3, 'X': 24, 'PART': 3, 'NUM': 5})\n",
      "defaultdict(<class 'int'>, {'INTJ': 464, 'ADV': 1388, 'PART': 632, 'VERB': 4243, 'PRON': 1204, 'NOUN': 3494, 'ADJ': 530, 'X': 1866, 'DET': 706, 'NUM': 137, 'CCONJ': 186, 'PROPN': 548, 'SCONJ': 71})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "changed_counts = defaultdict(int)\n",
    "total_counts = defaultdict(int)\n",
    "for elem in zip(tag_sents, source_sents, lemma_sents):\n",
    "    for i, (tag, word, lemma) in enumerate(zip(*elem)):\n",
    "        pos = tag.split(\",\")[0]\n",
    "        total_counts[pos] += 1\n",
    "        if word.lower() != lemma.lower():\n",
    "            changed_counts[pos] += 1\n",
    "print(changed_counts)\n",
    "print(total_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8285"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pairs, tags = [], []\n",
    "for elem in zip(tag_sents, source_sents, lemma_sents):\n",
    "    for i, (tag, word, lemma) in enumerate(zip(*elem)):\n",
    "        splitted = tag.split(\",\", maxsplit=1)\n",
    "        pos = splitted[0]\n",
    "        if pos in [\"VERB\", \"NOUN\", \"PROPN\"]:\n",
    "            word_pairs.append((lemma, word))\n",
    "            feats = splitted[1] if len(splitted) >= 2 else pos\n",
    "            tags.append((pos, feats))\n",
    "len(word_pairs)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcs_searcher = LcsSearcher(method=\"modified_Hulden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigms = lcs_searcher.calculate_paradigms(word_pairs, count_paradigms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigm_counts_by_tags = defaultdict(lambda: defaultdict(set))\n",
    "for (paradigm, fragments), (lemma, word), (pos, feats) in zip(paradigms, word_pairs, tags):\n",
    "    if pos == \"PROPN\":\n",
    "        pos = \"NOUN\"\n",
    "    paradigm = \"#\".join(paradigm)\n",
    "    paradigm_counts_by_tags[\",\".join([pos, feats])][paradigm].add(lemma)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../neural_tagging/results/low-resource/evenk-paradigm-stats.out\", \"w\", encoding=\"utf8\") as fout:\n",
    "    for descr, descr_data in sorted(paradigm_counts_by_tags.items()):\n",
    "        fout.write(\"{}\\t{}\\n\".format(descr, sum(len(x[1]) for x in descr_data.items())))\n",
    "        for pattern, lemmas in sorted(descr_data.items(), key=(lambda x:-len(x[1]))):\n",
    "            fout.write(\"{}\\t{}\\t{}\\n\".format(pattern, len(lemmas), \",\".join(lemmas)))\n",
    "        fout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
