{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import nmslib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as kbt\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "kbt.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_LM.UD_preparation.extract_tags_from_UD import read_tags_infile, make_UD_pos_and_tag\n",
    "from neural_tagging.neural_tagging_1 import load_tagger\n",
    "from neural_LM.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# переменные\n",
    "dev_file = \"/home/alexeysorokin/data/Data/UD2.3/UD_Russian-SynTagRus/ru_syntagrus-ud-train.conllu\"\n",
    "test_file = \"/home/alexeysorokin/data/Data/UD2.3/UD_Belarusian-HSE/be_hse-ud-test.conllu\"\n",
    "load_file = \"../neural_tagging/models/work/beruuk-large-5.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/alexeysorokin/data/Data/UD2.3/UD_Belarusian-HSE/be_hse-ud-test.conllu\n",
      "/home/alexeysorokin/data/Data/UD2.3/UD_Russian-SynTagRus/ru_syntagrus-ud-train.conllu\n"
     ]
    }
   ],
   "source": [
    "# читаем тестовую выборку\n",
    "test_data, test_source = read_tags_infile(test_file, read_words=True, return_source_words=True)\n",
    "dev_data, dev_source = read_tags_infile(dev_file, read_words=True, return_source_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 32, 91) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 32, 91) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 32, 32) 2912        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, 32, 50) 1650        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, 32, 100 6500        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, 32, 150 14550       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, 32, 200 25800       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, 32, 200 32200       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, 32, 200 38600       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, 32, 200 45000       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, 32, 110 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, 1100)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, None, 1100)   2422200     lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 1100)   0           highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 256)    1258496     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p (TimeDistributed)             (None, None, 350)    89950       bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 3,937,858\n",
      "Trainable params: 3,937,858\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cls = load_tagger(load_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(data, dataset_index=0, bucket_size=16):\n",
    "    dataset_codes = [dataset_index] * len(data)\n",
    "    transformed_data, indexes, _ = cls.transform(data, bucket_size=64, join_buckets=False, dataset_codes=dataset_codes)\n",
    "    answer = [[None] * len(data), [None] * len(data)]\n",
    "    for curr_indexes in indexes:\n",
    "        curr_batch = make_batch([transformed_data[i] for i in curr_indexes], {0: cls.symbols_number_})\n",
    "        curr_embeddings = cls._embedder_(curr_batch + [0])\n",
    "        for i, index in enumerate(curr_indexes):\n",
    "            L = len(data[index])\n",
    "            answer[0][index] = curr_embeddings[0][i,:L]\n",
    "            answer[1][index] = curr_embeddings[1][i,:L]\n",
    "    print(\"\")\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sents = [elem[0] for elem in test_data]\n",
    "test_embeddings = get_embeddings(test_sents, bucket_size=64)\n",
    "dev_sents = [elem[0] for elem in dev_data]\n",
    "dev_embeddings = get_embeddings(dev_sents, bucket_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = cls.predict(test_sents)\n",
    "dev_predictions = cls.predict(dev_sents, dataset_codes=[1] * len(dev_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SCONJ',\n",
       "  'ADV,Degree=Cmp',\n",
       "  'VERB,Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'NOUN,Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'PUNCT',\n",
       "  'VERB,Aspect=Imp|VerbForm=Inf|Voice=Act',\n",
       "  'ADJ,Case=Acc|Degree=Pos|Gender=Fem|Number=Sing',\n",
       "  'PRON,Case=Acc|Gender=Fem|Number=Sing|Person=3|PronType=Prs',\n",
       "  'VERB,Aspect=Perf|Mood=Ind|Number=Plur|Person=3|Tense=Fut|VerbForm=Fin|Voice=Act',\n",
       "  'ADP',\n",
       "  'NOUN,Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing',\n",
       "  'PUNCT',\n",
       "  'VERB,Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Gender=Neut|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing',\n",
       "  'NOUN,Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Gender=Fem|Number=Sing',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Gender=Fem|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing',\n",
       "  'PUNCT',\n",
       "  'NOUN,Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'PUNCT',\n",
       "  'PUNCT',\n",
       "  'VERB,Aspect=Imp|Tense=Pres|VerbForm=Conv|Voice=Act',\n",
       "  'NOUN,Animacy=Inan|Case=Acc|Gender=Fem|Number=Plur',\n",
       "  'NOUN,Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing',\n",
       "  'PRON,Case=Acc|Gender=Fem|Number=Sing|Person=3|PronType=Prs',\n",
       "  'PUNCT',\n",
       "  'NOUN,Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing',\n",
       "  'PUNCT',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing',\n",
       "  'PUNCT'],\n",
       " ['PART',\n",
       "  'DET,Case=Ins|Gender=Masc|Number=Sing|PronType=Ind',\n",
       "  'NOUN,Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Masc|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur',\n",
       "  'NOUN,Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Gender=Neut|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing',\n",
       "  'ADP',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Gender=Fem|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing',\n",
       "  'NOUN,Animacy=Anim|Case=Gen|Gender=Masc|Number=Plur',\n",
       "  'NUM,Case=Gen|NumType=Card',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing',\n",
       "  'ADP',\n",
       "  'NOUN,Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Masc|Number=Plur',\n",
       "  'PRON,Case=Acc|Gender=Fem|Number=Sing|Person=3|PronType=Prs',\n",
       "  'VERB,Aspect=Imp|VerbForm=Inf|Voice=Mid',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Gender=Fem|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing',\n",
       "  'ADP',\n",
       "  'NOUN,Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Gender=Fem|Number=Sing',\n",
       "  'CCONJ',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Gender=Fem|Number=Sing',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur',\n",
       "  'PUNCT'],\n",
       " ['CCONJ',\n",
       "  'NOUN,Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing',\n",
       "  'ADV,Degree=Pos',\n",
       "  'NOUN,Animacy=Anim|Case=Nom|Gender=Masc|Number=Plur',\n",
       "  'PUNCT',\n",
       "  'NOUN,Animacy=Inan|Case=Nom|Gender=Masc|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Neut|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing',\n",
       "  'VERB,Aspect=Imp|Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin|Voice=Mid',\n",
       "  'ADJ,Case=Ins|Degree=Pos|Number=Plur',\n",
       "  'PUNCT'],\n",
       " ['VERB,Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'PUNCT',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur',\n",
       "  'ADP',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing',\n",
       "  'PRON,Case=Acc|Gender=Fem|Number=Sing|Person=3|PronType=Prs',\n",
       "  'PART,Polarity=Neg',\n",
       "  'VERB,Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act'],\n",
       " ['NOUN,Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Gender=Fem|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing',\n",
       "  'PUNCT',\n",
       "  'ADJ,Case=Nom|Degree=Pos|Gender=Masc|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing',\n",
       "  'PUNCT',\n",
       "  'PUNCT',\n",
       "  'NOUN,Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'VERB,Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'VERB,Aspect=Imp|VerbForm=Inf|Voice=Act',\n",
       "  'PUNCT',\n",
       "  'SCONJ',\n",
       "  'ADJ,Case=Nom|Degree=Pos|Gender=Masc|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'PART,Polarity=Neg',\n",
       "  'VERB,Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Gender=Fem|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing',\n",
       "  'ADP',\n",
       "  'NOUN,Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur',\n",
       "  'ADP',\n",
       "  'NOUN,Animacy=Anim|Case=Nom|Gender=Masc|Number=Plur',\n",
       "  'PUNCT'],\n",
       " ['PUNCT',\n",
       "  'PRON,Animacy=Inan|Case=Nom|Gender=Neut|Number=Sing|PronType=Dem',\n",
       "  'PART,Polarity=Neg',\n",
       "  'NOUN,Animacy=Inan|Case=Nom|Gender=Fem|Number=Plur',\n",
       "  'PUNCT'],\n",
       " ['ADJ,Case=Nom|Degree=Pos|Gender=Masc|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'VERB,Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'ADV,Degree=Pos',\n",
       "  'NUM,Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing|NumType=Card',\n",
       "  'NOUN,Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing',\n",
       "  'ADV,Degree=Pos',\n",
       "  'ADJ,Case=Dat|Degree=Pos|Gender=Masc|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing',\n",
       "  'PUNCT'],\n",
       " ['PRON,Case=Acc|Gender=Fem|Number=Sing|Person=3|PronType=Prs',\n",
       "  'ADV,Degree=Pos',\n",
       "  'PART,Polarity=Neg',\n",
       "  'VERB,Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'ADP',\n",
       "  'NOUN,Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur',\n",
       "  'ADP',\n",
       "  'NOUN,Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing',\n",
       "  'ADP',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing',\n",
       "  'PUNCT',\n",
       "  'PUNCT',\n",
       "  'PUNCT',\n",
       "  'VERB,Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act',\n",
       "  'NOUN,Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'VERB,Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'PUNCT'],\n",
       " ['CCONJ',\n",
       "  'NOUN,Animacy=Inan|Case=Loc|Gender=Neut|Number=Plur',\n",
       "  'NOUN,Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing',\n",
       "  'PUNCT',\n",
       "  'ADJ,Case=Nom|Degree=Pos|Gender=Masc|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing',\n",
       "  'PUNCT',\n",
       "  'PUNCT',\n",
       "  'PUNCT',\n",
       "  'NOUN,Animacy=Inan|Case=Acc|Gender=Neut|Number=Sing',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Neut|Number=Plur',\n",
       "  'PUNCT',\n",
       "  'ADJ,Case=Nom|Degree=Pos|Gender=Neut|Number=Sing',\n",
       "  'ADP',\n",
       "  'NOUN,Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'NOUN,Animacy=Anim|Case=Gen|Gender=Masc|Number=Plur',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Masc|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur',\n",
       "  'PRON,Case=Acc|Gender=Fem|Number=Sing|Person=3|PronType=Prs',\n",
       "  'ADJ,Case=Gen|Degree=Pos|Gender=Neut|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing',\n",
       "  'PUNCT',\n",
       "  'AUX,Aspect=Imp|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'ADJ,Degree=Pos|Gender=Neut|Number=Sing|Variant=Short',\n",
       "  'ADV,Degree=Pos',\n",
       "  'ADV,Degree=Cmp',\n",
       "  'PUNCT',\n",
       "  'ADV,Degree=Pos',\n",
       "  'VERB,Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'ADP',\n",
       "  'PRON,Case=Gen|Number=Plur|Person=3',\n",
       "  'PART,Polarity=Neg',\n",
       "  'ADP',\n",
       "  'PRON,Animacy=Anim|Case=Ins|Gender=Masc|Number=Sing|PronType=Int',\n",
       "  'PART,Polarity=Neg',\n",
       "  'AUX,Aspect=Imp|Gender=Neut|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'PUNCT'],\n",
       " ['VERB,Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act',\n",
       "  'PART',\n",
       "  'ADV,Degree=Cmp',\n",
       "  'ADJ,Animacy=Inan|Case=Acc|Degree=Pos|Number=Plur',\n",
       "  'ADJ,Animacy=Inan|Case=Acc|Degree=Pos|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Acc|Gender=Fem|Number=Plur',\n",
       "  'PRON,Case=Acc|Gender=Fem|Number=Sing|Person=3|PronType=Prs',\n",
       "  'PUNCT',\n",
       "  'ADP',\n",
       "  'NOUN,Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing',\n",
       "  'NOUN,Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing',\n",
       "  'NOUN,Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing',\n",
       "  'PUNCT',\n",
       "  'PART,Polarity=Neg',\n",
       "  'VERB,Aspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'PUNCT',\n",
       "  'SCONJ,Mood=Cnd',\n",
       "  'PART,Polarity=Neg',\n",
       "  'VERB,Aspect=Imp|VerbForm=Inf|Voice=Act',\n",
       "  'ADJ,Animacy=Inan|Case=Acc|Degree=Pos|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Acc|Gender=Fem|Number=Plur',\n",
       "  'ADP',\n",
       "  'ADJ,Case=Ins|Degree=Pos|Number=Plur',\n",
       "  'NOUN,Animacy=Inan|Case=Ins|Gender=Masc|Number=Plur',\n",
       "  'PUNCT',\n",
       "  'VERB,Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act',\n",
       "  'PUNCT',\n",
       "  'ADJ,Animacy=Inan|Case=Acc|Degree=Pos|Gender=Masc|Number=Sing',\n",
       "  'NOUN,Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing',\n",
       "  'PUNCT',\n",
       "  'PUNCT']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random matrix to index\n",
    "vectors = np.random.randn(10000, 100).astype(np.float32)\n",
    "\n",
    "# initialize a new index, using a HNSW index on Cosine Similarity\n",
    "index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "index.addDataPointBatch(vectors)\n",
    "index.createIndex({'post': 2}, print_progress=True)\n",
    "\n",
    "# query for the nearest neighbours of the first datapoint\n",
    "ids, distances = index.knnQuery(vectors[0], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vectors_data(data, sents):\n",
    "    vectors, refs = [], []\n",
    "    for j, (sent_data, sent) in enumerate(zip(data, sents)):\n",
    "        for i, embedding in enumerate(sent_data):\n",
    "            vectors.append(embedding)\n",
    "            refs.append((i, sent))\n",
    "    vectors = np.array(vectors, dtype=\"float32\")\n",
    "    return vectors, refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors, test_refs = make_vectors_data(test_embeddings[1], test_source)\n",
    "dev_vectors, dev_refs = make_vectors_data(dev_embeddings[1], dev_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_vectors), len(dev_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = cdist(test_vectors[:1000], dev_vectors[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.argsort(distances)[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes[:100,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sents[334]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_source[334]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    pos, sent = test_refs[i]\n",
    "    start, end = max(pos-5, 0), min(pos+6, len(sent))\n",
    "    print(\"_\".join(sent[start:pos]), sent[pos], \"_\".join(sent[pos+1:end]))\n",
    "    index = indexes[i, 0]\n",
    "    dist = distances[pos, index]\n",
    "    pos, sent = dev_refs[index]\n",
    "    start, end = max(pos-5, 0), min(pos+6, len(sent))\n",
    "    print(index, \"{:.3f}\".format(dist), \"_\".join(sent[start:pos]), sent[pos], \"_\".join(sent[pos+1:end]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[layer.name for layer in cls.model_.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_distances[indexes[1000000:1000010]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "row_counts = defaultdict(int)\n",
    "for index in indexes[100000:1000000]:\n",
    "    i, j = index // distances.shape[1], index % distances.shape[1]\n",
    "    test_word = dev_refs[i][1][dev_refs[i][0]]\n",
    "    dev_word = dev_refs[j][1][dev_refs[j][0]]\n",
    "    if test_word == dev_word:\n",
    "        continue\n",
    "    row_counts[i] += 1\n",
    "    if not test_word.isdigit() and row_counts[i] < 5:\n",
    "        print(test_word, dev_word, \"{:.3f}\".format(flat_distances[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_index = nmslib.init(method='hnsw', space='l2')\n",
    "search_index.addDataPointBatch(dev_vectors)\n",
    "search_index.createIndex({'post': 2}, print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_refs[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, distances = index.knnQuery(test_vectors[23], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    pos, sent = test_refs[i]\n",
    "    start, end = max(pos-5, 0), min(pos+6, len(sent))\n",
    "    print(\"_\".join(sent[start:pos]), sent[pos], \"_\".join(sent[pos+1:end]))\n",
    "    indexes, distances = search_index.knnQuery(test_vectors[i], k=10)\n",
    "    for index, dist in zip(indexes[:3], distances[:3]):\n",
    "        pos, sent = dev_refs[index]\n",
    "        start, end = max(pos-5, 0), min(pos+6, len(sent))\n",
    "        print(\"{:.3f}\".format(dist), \"_\".join(sent[start:pos]), sent[pos], \"_\".join(sent[pos+1:end]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
